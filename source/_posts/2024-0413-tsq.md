---
title: about tcp small queue
date: 2024-04-13 22:03:46
tags:
- tcp
- linux
- kernel
- network
---

# TCP small queue

Reference:

1. https://lwn.net/Articles/507065/

2. https://lwn.net/Articles/506237/

3. https://abcdxyzk.github.io/blog/2018/03/23/kernel-tsq/

4. https://blog.csdn.net/wuyongmao/article/details/126246846

5. https://blog.csdn.net/wuyongmao/article/details/126247027

## overview

由于 qdisc （也可能有网络栈的其他地方） 可能存在 bufferbloat，导致很高的 latency，所以需要一些机制来防范。

TCP small queue 就是这样一种机制，它限制了每个 socket 可以发送的数据量，防止一个流太大，避免网络栈中 buffer 了过多的包。

具体限制可以看，比如下面这个机器上，是 1MB。

```
~ sudo cat /proc/sys/net/ipv4/tcp_limit_output_bytes
1048576
~ uname -r                  
5.15.0-26-generic
```

当到达 limit 之后就不允许 socket 继续发包， 只能存储在 socket 的缓存中。如果网卡发包完成后，释放skb的时候，如果发现该流达到 limit 了，就通过 tasklet 回调机制通知上层可以往协议栈继续发包了。这是一种 TCP 特有的协议栈内负反馈机制（比如 UDP 没有），解决了 TCP 流之间 的公平问题。

## impl

### 1. TCP 发送前

发送前会检查是否限流

```c
/* TCP Small Queues :
 * Control number of packets in qdisc/devices to two packets / or ~1 ms.
 * (These limits are doubled for retransmits)
 * This allows for :
 *  - better RTT estimation and ACK scheduling
 *  - faster recovery
 *  - high rates
 * Alas, some drivers / subsystems require a fair amount
 * of queued bytes to ensure line rate.
 * One example is wifi aggregation (802.11 AMPDU)
 */
static bool tcp_small_queue_check(struct sock *sk, const struct sk_buff *skb,
				  unsigned int factor)
{
	unsigned long limit;
	// 计算limit
    // ...
    
    if (static_branch_unlikely(&tcp_tx_delay_enabled) && tcp_sk(sk)->tcp_tx_delay) {
        // 模拟 TCP delay
    }
    if (refcount_read(&sk->sk_wmem_alloc) > limit) {
		// 由于 skb 发送后还没来得及调整 socket 的 wmem ...
        // 如果增大 window 的操作还在 tasklet 里面，那么立即发送。
		if (tcp_rtx_queue_empty_or_single_skb(sk))
			return false;
		// 设置限流 bit
		set_bit(TSQ_THROTTLED, &sk->sk_tsq_flags);
		/* It is possible TX completion already happened
		 * before we set TSQ_THROTTLED, so we must
		 * test again the condition.
		 */
		smp_mb__after_atomic();
		if (refcount_read(&sk->sk_wmem_alloc) > limit)
			return true;
	}

```

### 2. TCP 发送结束时

发送前，需要为所有数据包设置回调函数，NIC 发送完后会调用回调

```
	skb->destructor = skb_is_tcp_pure_ack(skb) ? __sock_wfree : tcp_wfree;
```

释放的 skb 的时候 (`kfree_skb`)会调用这个 tcp_wfree 的回调函数

```c

/*
 * Write buffer destructor automatically called from kfree_skb.
 * We can't xmit new skbs from this context, as we might already
 * hold qdisc lock.
 */
void tcp_wfree(struct sk_buff *skb)
{
    // ...
    // 清除 TSQF_THROTTLED 设置 TSQF_QUEUED
	oval = smp_load_acquire(&sk->sk_tsq_flags);
	do {
		if (!(oval & TSQF_THROTTLED) || (oval & TSQF_QUEUED))
			goto out;

		nval = (oval & ~TSQF_THROTTLED) | TSQF_QUEUED;
	} while (!try_cmpxchg(&sk->sk_tsq_flags, &oval, nval));

	/* queue this socket to percpu 的 tasklet queue */
	local_irq_save(flags);
	tsq = this_cpu_ptr(&tsq_tasklet);
	empty = list_empty(&tsq->head);
	list_add(&tp->tsq_node, &tsq->head);
	if (empty)
		tasklet_schedule(&tsq->tasklet);
	local_irq_restore(flags);
	return;
out:
	sk_free(sk);
}

```

### 4. 相关 tasklet

相关 tasklet 初始化

```c
/* TCP SMALL QUEUES (TSQ)
 *
 * TSQ goal is to keep small amount of skbs per tcp flow in tx queues (qdisc+dev)
 * to reduce RTT and bufferbloat.
 * We do this using a special skb destructor (tcp_wfree).
 *
 * Its important tcp_wfree() can be replaced by sock_wfree() in the event skb
 * needs to be reallocated in a driver.
 * The invariant being skb->truesize subtracted from sk->sk_wmem_alloc
 *
 * Since transmit from skb destructor is forbidden, we use a tasklet
 * to process all sockets that eventually need to send more skbs.
 * We use one tasklet per cpu, with its own queue of sockets.
 */
struct tsq_tasklet {
	struct tasklet_struct	tasklet;
	struct list_head	head; /* queue of tcp sockets */
};
static DEFINE_PER_CPU(struct tsq_tasklet, tsq_tasklet);

// 初始化
void __init tcp_tasklet_init(void)
{
	int i;

	for_each_possible_cpu(i) {
		struct tsq_tasklet *tsq = &per_cpu(tsq_tasklet, i);

		INIT_LIST_HEAD(&tsq->head);
		tasklet_setup(&tsq->tasklet, tcp_tasklet_func);
	}
}
```

TSQ 的 tasklet 函数 tcp_tasklet_func 如下，由于之前加入到了很多 `tsq->head`，清除 TSQ_QUEUED 标志，调用 TSQ 的核心处理函数 tcp_tsq_handler。

```c
/*
 * One tasklet per cpu tries to send more skbs.
 * We run in tasklet context but need to disable irqs when
 * transferring tsq->head because tcp_wfree() might
 * interrupt us (non NAPI drivers)
 */
static void tcp_tasklet_func(struct tasklet_struct *t)
{
	struct tsq_tasklet *tsq = from_tasklet(tsq,  t, tasklet);
	LIST_HEAD(list);
	unsigned long flags;
	struct list_head *q, *n;
	struct tcp_sock *tp;
	struct sock *sk;

	local_irq_save(flags);
	list_splice_init(&tsq->head, &list);
	local_irq_restore(flags);

	list_for_each_safe(q, n, &list) {
		tp = list_entry(q, struct tcp_sock, tsq_node);
		list_del(&tp->tsq_node);

		sk = (struct sock *)tp;
		smp_mb__before_atomic();
		clear_bit(TSQ_QUEUED, &sk->sk_tsq_flags);

		tcp_tsq_handler(sk);
		sk_free(sk);
	}
}
```

TSQ 的核心处理函数 tcp_tsq_handler，当没有被用户 hold sock 时，则会调用 tcp_write_xmit 进行发送

```c
static void tcp_tsq_handler(struct sock *sk)
{
	bh_lock_sock(sk);
    // 如果 sk 没有被 user hold，则调用发送函数
	if (!sock_owned_by_user(sk))
		tcp_tsq_write(sk);
    // 否则设置 TCP_TSQ_DEFERRED 表示延迟处理
	else if (!test_and_set_bit(TCP_TSQ_DEFERRED, &sk->sk_tsq_flags))
		sock_hold(sk);
	bh_unlock_sock(sk);
}

static void tcp_tsq_write(struct sock *sk)
{
	if ((1 << sk->sk_state) &
	    (TCPF_ESTABLISHED | TCPF_FIN_WAIT1 | TCPF_CLOSING |
	     TCPF_CLOSE_WAIT  | TCPF_LAST_ACK)) {
		struct tcp_sock *tp = tcp_sk(sk);

		if (tp->lost_out > tp->retrans_out &&
		    tcp_snd_cwnd(tp) > tcp_packets_in_flight(tp)) {
			tcp_mstamp_refresh(tp);
			tcp_xmit_retransmit_queue(sk);
		}

		tcp_write_xmit(sk, tcp_current_mss(sk), tp->nonagle,
			       0, GFP_ATOMIC);
	}
}
```

若被 hold sock，则等待 sock_release 的时候调用 tcp_release_cb，进行一系列延时处理（包括 TSQ 的延时处理

```c
void tcp_release_cb(struct sock *sk)
{
	unsigned long flags = smp_load_acquire(&sk->sk_tsq_flags);
	unsigned long nflags;

	/* perform an atomic operation only if at least one flag is set */
	do {
		if (!(flags & TCP_DEFERRED_ALL))
			return;
		nflags = flags & ~TCP_DEFERRED_ALL;
	} while (!try_cmpxchg(&sk->sk_tsq_flags, &flags, nflags));

	if (flags & TCPF_TSQ_DEFERRED) {
		tcp_tsq_write(sk);
		__sock_put(sk);
	}

```

另外，关于 socket ownership: https://abcdxyzk.github.io/blog/2018/01/04/kernel-net-sk-lock/

> tcp 协议栈对 `struct sock *sk`有两把锁，第一把是 sk_lock.slock，第二把则是 sk_lock.owned。sk_lock.slock 用于获取 `struct sock* sk` 对象的成员的修改权限；sk_lock.owned用于区分当前是进程上下文或是软中断上下文，为进程上下文时 sk_lock.owned 会被置1，中断上下文为0。
>
> 如果是要对sk修改，首先是必须拿锁 sk_lock.slock，其后是判断当前是软中断或是进程上下文，如果是进程上下文，那么一般也不能修改sk
>
> 获得sk_lock.slock 锁后还要判断 sock_owned_by_user(sk), 如果被进程上下文占用也一般不能操作sk

一般在对 socket 进行配置的时候，比如 `sock_set_reuseaddr` 修改 socket 属性，就需要 ownership。

## 总结

总的来说，TSQ 是个状态机，init -> TSQ_THROTTLED -> TSQ_QUEUED -> TCP_TSQ_DEFERRED

TSQ_THROTTLED: 发送时，表示限流不准发了

TSQ_QUEUED：网卡发送后释放 skb 时，清除限流标志，设置为 TSQ_QUEUED，表示还有数据因为被限流没有发送，进入 tasklet 中发送。

TSQ_TSQ_DEFERRED: 在 tasklet 准备发送数据时，发现 sock 被 user lock 了，需要等待 user release sock 释放锁后，调用回调函数 tcp_release_cb (即 release_sock 的 callback 函数)，继续进行发送。
