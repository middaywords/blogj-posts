---
title: [译]《TCP CC - a systems approach》notes (2) - loss-based cc
date: 2024-05-02 23:17:04
tags:
- network
---

# 《TCP CC: a systems approach》notes 2: control-based ccß

Link: https://tcpcc.systemsapproach.org/index.html 

概括总结 by kimi

前一节 introduction 最后说到 implementation choices 主要有两种，一种是 control-based，一种是 avoidance-based。这一节介绍其一。

## 4.1 Timeout calculation

超时和重传是TCP实现可靠字节流的核心部分，超时也在拥塞控制中起着关键作用，因为它们标志着数据包丢失，这反过来又表明了可能发生了拥塞。换句话说，TCP的超时机制是其整体拥塞控制方法的一个基础(building block)。

### original algorithm

我们从最初在TCP规范中描述的简单算法开始。该算法的目的是保持一个RTT（往返时间）的运行平均值，然后根据这个RTT来计算超时。具体来说，每次TCP发送一个数据段时，它会记录时间。当该段的确认（ACK）到达时，TCP再次读取时间，并取这两个时间的差值作为样本RTT。然后TCP计算估计RTT（EstimatedRTT）作为之前估计和这个新样本的加权平均值。
$$
\mathsf{EstimatedRTT} = \alpha \times \mathsf{EstimatedRTT} + (1 - \alpha{}) \times \mathsf{SampleRTT}
$$
参数 alpha 用于平滑 EstimatedRTT，一般选择 0.8-0.9，不会导致有误差的数据带来较大偏移。TCP 会使用 EstimatedRTT 计算 timeout
$$
\mathsf{TimeOut = 2} \times \mathsf{EstimatedRTT}
$$

### Karn/Partridge算法

几年后，人们发现这种简单方法存在一个明显的问题：一个ACK实际上并不确认一次传输，而是确认数据的接收。换句话说，每当一个段被重传，然后ACK到达发送方时，我们无法确定这个ACK应该关联第一次还是第二次重新传输的段。

为了解决这个问题，Karn和Partridge提出了一个简单的解决方案，即Karn/Partridge算法。根据这个算法，**每当TCP重传一个段时，它就停止采集RTT的样本；**它只对仅发送一次的段测量SampleRTT。

但是，这个算法还包括对TCP超时机制的另一个改变。每次TCP重传时，它将下一个超时设置为最后一个超时的两倍，而不是基于上一个EstimatedRTT。也就是说，Karn和Partridge提出超时计算应该使用指数退避。使用指数退避的动机是，超时会导致重传，而重传的段不再对RTT估计的更新做出贡献。因此，这个想法是在声明数据包丢失时更加谨慎，而不是进入一个积极超时然后重传的可能循环中。

#### Jacobson/Karels算法

Karn/Partridge算法改进了RTT估计，但并没有消除拥塞。1988年由Jacobson和Karels提出的拥塞控制机制包括（除了其他几个组件外）一种新的方式来决定何时超时和重传一个段。

原始计算的主要问题在于它没有考虑样本RTT的方差。直观上，如果样本之间的变化很小，那么EstimatedRTT就可以被更可信地依赖，并且没有必要将这个估计乘以2来计算超时。另一方面，样本的大变化表明超时值不应该太紧密地与EstimatedRTT耦合。

在新的方法中，发送方像以前一样测量新的SampleRTT。然后，它将这个新样本纳入超时计算中，如下所示：
$$
\mathsf{Difference = SampleRTT - EstimatedRTT} 
$$
$$
\mathsf{EstimatedRTT = EstimatedRTT} + ( \delta \times \mathsf{Difference)}
$$

$$
\mathsf{Deviation = Deviation} + \delta \mathsf{(| Difference | - Deviation)}
$$



其中，δ是一个介于0和1之间的参数。也就是说，我们计算RTT的加权移动平均值以及它的方差的加权移动平均值。然后，TCP根据EstimatedRTT和Deviation计算超时值，如下所示：
$$
\mathsf{TimeOut} = \mu \times \mathsf{EstimatedRTT} + \phi \times \mathsf{Deviation}
$$
其中，μ基于经验通常设置为1，而φ设置为4。因此，当变化很小时，TimeOut接近EstimatedRTT；大的变化会使Deviation项支配计算。



---

4.2-4.4 略



## 4.5 incremental enhancements

如果对TCP拥塞控制的研究教会了我们一件事，那就是这个问题的复杂性，以及你必须正确处理的许多细节。这只能通过一系列基于经验的增量改进来实现。以下提供了两个额外的例子。

### SACK

> [RFC 2018 - TCP Selective Acknowledgment Options (ietf.org)](https://datatracker.ietf.org/doc/html/rfc2018)

原始的TCP规范使用累积确认，这意味着接收方确认的是它接收到的最后一个数据包，该数据包在任何丢失的数据包之前。你可以想象接收方有一系列已接收的数据包，其中任何丢失的数据包都由接收字节流中的空白表示。直观地说，这种缺乏细节可能会限制发送方对数据包丢失的有效响应。解决这个问题的方法被称为选择性确认或SACK。SACK是TCP的另一个可选扩展，最初在Jacobson和Karels的早期工作之后不久被提出，但花了几年时间才获得认可，因为很难证明它会有益。

没有SACK的情况下，发送方在接收到乱序的段时只有两种合理的策略。悲观策略对重复的ACK或超时响应，不仅重传明显丢失的段（即接收方缺失的第一个数据包），而且重传随后传输的所有段。实际上，悲观策略假设最坏的情况：所有这些段都丢失了。悲观策略的缺点是，它可能会不必要地重传第一次就成功接收的段。另一种策略是，对丢失信号（超时或重复ACK）响应，只重传触发该信号的段。这种乐观的方法假设最好的情况：只有一段丢失了。乐观策略的缺点是，当一系列连续的段丢失时，它的恢复速度非常慢，就像在拥塞时可能发生的那样。它之所以慢，是因为直到发送方接收到对之前段重传的ACK，才会发现每一段的丢失。这意味着它消耗了一个RTT来重传丢失系列中的每个段。有了SACK选项，发送方可以采用更好的策略：只重传填补已选择性确认的段之间的空白的段。

SACK在连接开始时通过发送方告诉接收方它可以处理SACK选项来进行协商。当使用SACK选项时，接收方继续正常确认段——确认字段的含义没有改变——但它还扩展了头部，为任何乱序接收的块提供额外的确认。这允许发送方识别接收方存在的空白，并只重传缺失的段，而不是所有在丢失段之后传输的段。

SACK被证明在单个RTT期间多个数据包被丢弃的情况下，特别是在TCP Reno中，可以改善性能，因为这是预期的（因为当只有一个数据包丢失时，累积ACK和SACK是相同的）。随着 BDP 的增加，这种情况变得更加可能，因为在一个给定的RTT中，管道中有更多的数据包。因此，SACK在1996年成为IETF提出的标准，是对TCP的一个及时的补充。

## 4.6 cubic

尝试找到向网络发送流量的适当速率是拥塞控制的核心，而且可能在任一方向上犯错误。发送太少的流量会导致网络未被充分利用，从而导致应用程序性能不佳。发送过多的流量则会导致网络拥塞，在最坏的情况下可能导致拥塞崩溃。在这两种失败模式之间，发送过多的流量通常是更严重的问题，因为拥塞可以迅速自我加剧，因为丢失的数据包会被重传。Tahoe、Reno和NewReno内置的AIMD（加性增加/乘性减少）方法反映了这一点：缓慢增加窗口（加性增加）和快速减少窗口（乘性减少），努力在拥塞崩溃变得太严重之前退一步。但在高带宽延迟环境中，过于保守地探测拥塞的代价是相当高的，因为可能需要许多个RTT（往返时间）才能使“管道充满”。因此，这导致了对如何探测适当窗口大小的一些重新思考。

**窗口有时应该快速增加，有时应该更慢地打开的想法**。二进制增加拥塞控制（BIC）提出了这种想法。BIC不是像TCP Reno那样突然从指数窗口增长切换到线性，而是有效地对“正确”的窗口大小进行了二进制搜索。在数据包丢失后，拥塞窗口被乘性因子β减少。随着在新窗口大小下成功发送数据包的每次迭代，窗口增加到当前值和导致拥塞的旧值的中点。通过这种方式，**它逐渐逼近旧值——首先快速然后缓慢。**

![](https://tcpcc.systemsapproach.org/_images/Slide9.png)

> Figure 28. *Generic cubic function illustrating the change in the congestion window as a function of time.*

在这一点上，如果没有拥塞，我们可以得出结论，网络条件已经改变，并且可以探测新的拥塞窗口大小。BIC首先缓慢然后更快速地这样做。你可以在 Figure 28中看到BIC增长窗口的大致形状，逼近（上一次丢失之前的拥塞窗口）然后超越它。

BIC最终演变成一个称为CUBIC的新变种，今天它是与Linux一起分发的默认拥塞控制算法。CUBIC在多个方面改进了BIC，其中之一是使用由三次函数描述的平滑曲线，而不是BIC的分段线性函数。下面将对此进行更多讨论。

CUBIC方法的另一个重要方面是，它**根据自上次拥塞事件**（例如，重复ACK的到来）以来经过的时间量来调整其拥塞窗口，而不仅仅是在收到ACK时（后者是RTT的函数）。**这允许CUBIC在长RTT流与短RTT流竞争时表现得更公平，后者的ACK到达更频繁**。这是一个与早期TCP版本有趣的不同之处，在早期版本中，短RTT的流在获得瓶颈链路的份额方面肯定有优势。

三次函数在图28中显示，有三个阶段：增长放缓、平坦的平台、增加增长。在上一次拥塞事件之前达到的最大拥塞窗口大小是初始目标（表示为Wmax）。你可以看到窗口增长开始很快，但当接近Wmax时减慢；然后在接近Wmax时有一个谨慎增长的阶段，最后是探测新的可实现Wmax的阶段。

具体来说，CUBIC将拥塞窗口（CongestionWindow）计算为自上次拥塞事件以来的时间（t）的函数:
$$
\mathsf{CongestionWindow(t)} = \mathsf{C} \times \mathsf{(t-K)}^{3} + \mathsf{W}{max}
$$
其中
$$
\mathsf{K} =  \sqrt[3]{\mathsf{W}{max} \times (1 - \beta{})/\mathsf{C}}
$$
C是一个缩放常数，β是乘性减小时使用的因子。CUBIC将后者设置为0.7，而不是标准TCP使用的0.5。回顾 Figure 28，CUBIC通常被描述为在凹函数和凸函数之间转换（而标准TCP的 additive increase 阶段只是凸的）。

有趣的是，CUBIC根据条件比早期的TCP变种更具侵略性或更保守。短RTT的TCP Reno流倾向于在获取瓶颈带宽方面非常有效，因此CUBIC包括一个“TCP友好”模式，目标是和TCP Reno一样积极。但在其他情况下，特别是在高带宽延迟网络中，CUBIC将能够获得更大的瓶颈带宽份额，因为CUBIC正在**更快地增加其窗口大小**。这让我们回到了第3.3节的讨论，即**对现有算法的“公平性”是否是正确的设计目标**。最终，CUBIC经过了广泛的分析，显示出在许多条件下的良好性能，没有造成不当的伤害，并已被广泛部署。
