---
title: [译] UEC white paper
date: 2025-04-24 22:48:11
tags:
- network
---

原文链接 UEC whitepaper https://ultraethernet.org/wp-content/uploads/sites/20/2023/10/23.07.12-UEC-1.0-Overview-FINAL-WITH-LOGO.pdf

## 1. 未来 AI 和 HPC 网络的需求

（对高速网络的需求从来如此

- larger scale
- higher bandwidth
- support delivery of messages to all participating endpoints as quickly as possible, without long delays for even a few endpoints. **“Tail latency” should be minimized**.

为了实现 low tail latency，UEC 在以下方面做出设计，包括：

1. Multi-pathing and packet spraying
2. Flexible delivery order
3. Modern congestion control mechanisms
4. End-to-end telemetry
5. Larger scale, stability, and reliability

现有技术都有些不足，UEC 需要解决他们

### 1.1 Multi-Pathing and Packet Spraying

传统的以太网网络基于生成树协议(STP, spanning tree protocol)，确保从 A 到 B 只有一条路径，以避免网络中的环路。随后出现了多路径技术，如等价成本多路径（ECMP），网络尝试利用尽可能多的链路来连接通信伙伴。ECMP通常使用“流哈希”将给定的四层流量发送到一条路径，同时将不同的流量映射到不同的路径。然而，这仍然限制了高吞吐量流量只能使用一条路径。此外，当多路径技术将过多的流量映射到单个网络路径时，网络性能会下降，因此需要谨慎管理负载均衡以实现最佳性能。技术演进的下一阶段是**让每个流量同时使用所有到达目的地的路径，这种技术被称为“数据包喷洒”**，从而实现更均衡地使用所有网络路径。

### 1.2 Flexible Ordering

旧技术的限制：

- 旧技术使用的严格数据包排序（例如，Verbs API要求的排序）限制了效率，因为它阻止了乱序数据包直接从网络传输到应用程序缓冲区，即主机内存中的最终位置。
- 这种限制，加上回退N（Go-Back-N）数据包丢失恢复机制（它迫使重新传输多达N个数据包以补偿单个丢失的数据包），导致可用链路未被充分利用，并增加了尾部延迟

这对于大规模AI应用是不够的。理想情况下，所有链路都被使用，只有在AI工作负载需要时才强制排序。

AI工作负载中的许多加速器间通信是“集体”通信操作的一部分，其中All-Reduce和All-to-All是主要的集体类型。快速完成这些操作的关键在于从A到B的快速批量传输，**AI应用程序只关心给定消息的最后一部分何时到达目的地。灵活的排序使这一过程能够高效完成。它也使得在带宽密集型集体操作中利用数据包喷洒的优势成为可能，**因为不需要在将数据包传递给应用程序之前重新排序。当应用程序适用时，**支持现代API以放宽逐包排序要求对于减少尾部延迟至关重要**。

### 1.3 AI and HPC Optimized Congestion Control

网络拥塞可能发生在三个地方：

- 从发送方到第一个交换机的出链路
- 第一个交换机和最后一个交换机之间的链路
- 最后一个交换机和接收方之间的最终链路

对于AI和高性能计算（HPC），发送方出链路上的拥塞主要可以通过发送主机上的调度算法来控制，因为发送主机可以看到所有出站流量。上述的多路径数据包喷洒技术通过在所有路径上均匀分布负载，**来最大限度地减少第一个交换机和最后一个交换机之间的热点和拥塞**。**最后一种形式的拥塞——“汇聚”（Incast）——发生在最后一条到接收方的链路上，当多个发送方同时向同一目的地发送流量时，就会发生这种情况**；这可能是前面提到的“All-to-All”通信的一部分。

近年来，针对拥塞问题提出了许多解决方案（例如，DCQCN、DCTCP、SWIFT、Timely）。然而，目前没有一种算法能够满足为AI优化的传输协议的所有需求，这些需求包括：

- 在高速、低往返时间的网络中快速提升到线路速率，当存在无拥塞路径时，不降低现有流量的性能
- 管理网络结构中的路径拥塞以及到目的地的最后一跳拥塞
- 通过公平共享最后的链路来控制汇聚（Incast），避免昂贵的数据包丢失、重传或增加尾部延迟
- 不需要随着流量混合变化、计算节点演变、链路速度增加和网络硬件演变进行调优和配置

未来AI工作负载的拥塞控制算法必须设计成既支持这些需求，又能与多路径数据包喷洒技术协同工作。这意味着开发一种能够动态适应网络条件变化的智能算法，以确保高效的数据传输和资源利用，同时减少配置和调优的复杂性。

### 1.4 End-to-End Telemetry

优化的拥塞控制算法得益于新兴的端到端遥测方案。这些方案

- 使网络中的拥塞源信息能够通知参与者拥塞的位置和原因。
- 缩短拥塞信号路径并向端点提供更多信息，可以实现更具响应性的拥塞控制。
- 无论是发送方还是接收方进行传输调度，现代交换机都可以通过快速传递准确的拥塞信息给调度器或节拍器来促进响应性拥塞控制，从而提高拥塞控制算法的响应性和准确性。

结果是减少了拥塞、降低了丢包率和缩小了队列——所有这些都服务于改善尾部延迟。

这种端到端遥测方案通过

- 实时监测网络状态，使得数据传输更加高效和可靠。
- 交换机能够快速传递拥塞信息，使得算法能够及时调整传输策略，从而减少不必要的数据包重传和延迟。

这种改进不仅提高了网络资源的利用率，还为AI和高性能计算应用提供了更稳定的网络环境。随着技术的发展，这种方法将成为优化网络性能的重要工具。

## 2. RDMA 的成功之处以及它的问题

随着AI模型规模的扩大以及通信模式和计算方法的多样化，是时候重新审视大多数AI网络核心所采用的传输协议和API了。通常，远程直接内存访问（RDMA）是一种非常成功的技术，它允许CPU、GPU、TPU或其他加速器直接从发送方的内存传输数据到接收方的内存。这种零拷贝方法带来了低延迟，并避免了操作系统的开销。因此，支持RDMA的网络技术是当前AI训练任务的基本组成部分。

RDMA over Converged Ethernet（RoCE）被创建出来，以允许IBTA（InfiniBand™ Trade Association）的RDMA传输协议在IP和以太网网络上运行。该底层协议通过Verbs API表达，是在上个世纪末设想并由IBTA在多年前首次标准化的。如今，它在面对现代高需求AI网络流量时显得有些过时（参见《Data Center Ethernet and Remote Direct Memory Access: Issues at Hyperscale》，Hoefler等，发表于《Computer》，2023年7月）。问题不在于操作系统绕过和零拷贝的通用RDMA原则，也不在于使用以太网网络，**而是在于RoCE和InfiniBand所共同使用的当前传输协议服务。**

《Data Center Ethernet and Remote Direct Memory Access: Issues at Hyperscale》: https://arxiv.org/abs/2302.03337

1. （问题：速度超过预料）截至目前，一个单一加速器可能集成了多个Tb的网络I/O，而PCIe网卡将很快提供800Gbps及以上的速度——远远快于RDMA最初设想时的速度。未来更高要求和更高速的网络将进一步挑战现状，并需要新的解决方案。

解决方案：为了适应这些变化，AI网络需要重新考虑其底层传输协议，以支持更高的速度和更复杂的通信模式。这可能**包括开发新的API接口和协议，以更好地利用现代硬件的能力，并确保在高负载下的稳定性和效率。**通过创新和改进，AI网络可以继续支持不断增长的模型和计算需求。

2. （问题：调参麻烦，自适应能力差）在使用RoCE时，通常会采用DCQCN作为拥塞控制算法，以避免在网络中超载链接，同时尝试快速提高传输速率。然而，DCQCN的性能调优需要仔细的手动调整，因为它对底层网络的延迟、速度和缓冲能力，以及在其上通信的工作负载性质都很敏感。TCP/IP协议套件的一个巨大成功在于，TCP不需要针对网络进行调优，并且可以“即插即用”。未来的AI网络需要一种传输协议，像TCP一样，可以在任何数据中心网络中“开箱即用”。

3. （问题：go-back-N 效率低，PFC问题太多）众所周知，虽然InfiniBand和RoCE中使用的RDMA传输可以处理丢失的数据包，但其效率很低。丢失或乱序的数据包会导致“回退N”恢复，其中已经接收到的数据包被重新传输，导致较低的“有效吞吐量”和较差的效率。网络运营商经常在“无损”网络上运行RDMA，以避免触发这种行为。如果配置以太网，使其在拥塞时从接收方向发送方生成逐跳反压力，使用优先级流量控制（PFC），以太网可以是无损的。因此，与其丢弃数据包，不如在前一个跳点延迟其传输。然而，当这种反压力在网络中传播时，会产生“拥塞树”和线头阻塞，这两者在规模上都可能导致严重的性能下降。

解决方案：为了解决这些问题，未来的AI网络需要**开发新的拥塞控制机制和传输协议，以提高数据传输的效率和鲁棒性。这可能包括自动调优算法，以减少人工干预的需求，以及更智能的丢包处理方法，以提高网络的整体性能。**在设计这些新系统时，必须考虑到网络的动态特性和AI工作负载的复杂需求，以确保在高负载和复杂通信模式下的稳定性和效率。

虽然大型无损RoCE网络可以成功部署，但它们需要仔细的调优、操作和监控，以便在不触发负面效应的情况下良好运行。这种投资和专业知识的水平并不是所有网络运营商都能负担得起的，导致总拥有成本（TCO）较高。因此，**需要一种不依赖于无损网络结构的传输协议。**

4. （问题：RC 不高效）此外，RoCE和InfiniBand使用的API（Verbs）是为较低规模设计的——无论是在带宽方面还是在对等节点数量方面——这与现代AI和高性能计算（HPC）任务以及未来集成网络的加速器所需的规模不符。**RC（可靠连接）传输模式不适合在高速情况下实现高效的硬件卸载，因为这需要减少快速路径状态。虽然有一些专有的尝试来解决RC的局限性，但这些尝试都没有被广泛接受，也没有完全解决其固有的进程对进程（Process to Process，P2P）可扩展性问题。**虽然RC的实现可以在适度规模上工作，但它增加了端点的成本和复杂性，对于未来大规模的AI任务来说是一个负担，因此需要新的解决方案。

5. （负载均衡做的不好容易单个链接过载）最后，AI应用程序传输大量数据。传统的RoCE将这些数据作为少量的大流进行传输，必须仔细进行负载均衡以防止任何单个链接过载，如上所述。AI工作负载通常在所有流成功传输之前无法继续，甚至一个过载的链接都会限制整个计算。因此，**改进负载均衡技术**对于提高AI性能至关重要。

解决方案：为了应对这些挑战，未来的网络解决方案需要具备**自动化调优能力、适应性强的负载均衡机制**，以及能够支持大规模并行处理的传输协议。这将有助于降低总拥有成本，提高网络效率，并支持AI和HPC任务的不断增长的需求。通过创新的网络架构和协议设计，能够在不依赖无损网络的情况下实现高效的数据传输和处理。

## 3. UEC 的理念

Ultra Ethernet Consortium的成员认为，现在是时候从头开始，用Ultra Ethernet Transport替代传统的RoCE协议。这是一种现代传输协议，旨在提供AI和HPC应用所需的性能，同时保留以太网/IP生态系统的优势。

从TCP/IP和以太网的成功中吸取的两个基本教训是：传输协议应该提供丢失恢复功能，并且无损网络结构在操作时非常具有挑战性，容易触发 Head-of-line blocking(HoL) 阻塞和 congestion spreading。基于这些原则，UEC传输协议建立在分布式路由算法和基于端点的可靠性与拥塞控制的基础上。UEC传输协议通过以下功能超越现状：

- 开放的协议规范，从一开始就设计为在IP和以太网上运行。
- 多路径、数据包喷射传输，充分利用AI网络而不会导致拥塞或 HoL block，消除了对集中负载均衡算法和路由控制器的需求。
- incast management 机制，控制到目标主机的最终链接的汇聚，尽量减少丢包。
- 高效的速率控制算法，使传输能够快速达到线速，同时不会导致竞争流的性能损失。
- 支持乱序数据包传递的API，并可选择性地完成消息的顺序传递，最大化网络和应用的并发性，最小化消息延迟。
- 支持未来网络的扩展，能够支持多达1,000,000个端点。
- 性能和最佳网络利用率，无需针对网络和工作负载的拥塞算法参数调优。
- 设计旨在在商品硬件上实现 line rate，支持未来800G、1.6T及更快的以太网网络。

UEC规范将超越传输层，定义标准语义层、改进低延迟传输机制，以及一致的AI和HPC API，提供标准的多厂商支持以在UEC传输协议上实现这些API。

通过这些创新，UEC旨在为AI和HPC应用提供一个强大的传输解决方案，能够支持现代和未来网络的需求，同时简化操作并降低成本。通过开放和标准化的设计，UEC有望成为下一代网络传输协议的基础。



## 4. Security for AI & HPC

AI训练和推理通常发生在需要作业隔离的托管网络中。此外，AI模型越来越敏感，并且是有价值的商业资产。鉴于此，UEC传输协议在设计时就纳入了网络安全功能，可以对AI训练或推理作业中计算端点之间发送的所有网络流量进行加密和认证。UEC传输协议利用了现代加密方法（如IPSec和PSP）的成熟核心技术，以实现高效的会话管理、认证和保密。

随着作业规模的扩大，支持加密而不使主机和网络接口中的会话状态膨胀变得必要。为此，UET引入了新的密钥管理机制，允许参与作业的数万个计算节点之间高效共享密钥。它被设计为能够在AI训练和推理所需的高速和规模上高效实现。

托管在大型以太网网络上的HPC作业具有类似的特征，并需要类似的安全机制。



## 5. Further Efforts in UEC - HPC and Beyond

除了促进AI网络的改进，UEC还在开发技术以支持未来高性能计算（HPC）的网络需求。展望未来，预计AI和HPC的工作负载及网络需求将越来越重叠。因此，我们期望UEC传输协议能够满足AI和HPC作业的网络需求。

鉴于带宽和延迟的不同敏感性，UEC规范将提供两个配置文件——一个优化用于AI，另一个优化用于HPC。随着速度和规模的增加，传统仅依赖端到端重试的方法对于延迟敏感的工作负载来说越来越繁琐。在链路层进行局部错误处理(FEC) 已经在扩展型HPC网络中证明了其价值，例如用于百亿级系统的网络。UEC规范为以太网提供了这种能力。

## 6. Summary

AI系统通常部署在具有多条从发送者到接收者路径的网络拓扑上。关键在于同时高效地利用这条昂贵的“高速公路”的所有通道。为实现这一目标，需要具备可扩展且高效的远程内存访问，并通过数据包喷洒、灵活排序和优化的拥塞控制算法来实现。此外，新的端到端遥测、可扩展的安全性以及AI优化的API将对于优化网络以满足未来密集AI计算的独特通信需求至关重要。

UEC协议也被设计用于支持现代HPC工作负载，利用上述相同的传输机制，同时保留广泛使用的API，如MPI和PGAS。

UEC的创始成员包括当今许多最大AI和HPC网络的供应商和运营商。UEC的工作利用了其成员多年构建和运营这些网络的经验。即将发布的UEC草案规范将开放使用，作为AI和HPC网络的互操作基础。UEC正在开发的技术将产生持久影响，提高未来要求苛刻的AI和HPC应用的性能、易用性和成本。
